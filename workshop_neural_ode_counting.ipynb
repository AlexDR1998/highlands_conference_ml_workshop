{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural ODEs\n",
    " - In this notebook we will train a neural differential equation to map images of each MNIST integer to the next one along\n",
    " - We will make use of the autoencoder style network used in the autoencoder workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as np\n",
    "import jax.random as jr\n",
    "import optax\n",
    "import equinox as eqx \n",
    "import einops\n",
    "import diffrax \n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "key = jr.PRNGKey(SEED) # JAX is very explicit with pseudo-random numbers, such that everything can be kept as a \"pure\" function when needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading is a bit different now\n",
    "- We need to sort our dataset by what the integers are\n",
    "- Now the batch index selects what number the image represents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5421, 1, 28, 28)\n",
      "(5421, 9, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train[:,np.newaxis] / 255.0\n",
    "x_test = x_test[:,np.newaxis] / 255.0\n",
    "\n",
    "#x_train = x_train - einops.reduce(x_train,\"B i x y -> B i () ()\",\"mean\")\n",
    "#x_test = x_test - einops.reduce(x_test,\"B i x y -> B i () ()\",\"mean\")\n",
    "\n",
    "\n",
    "x_train_grouped = []\n",
    "lengths = []\n",
    "for i in range(10):\n",
    "    x_train_grouped.append(x_train[y_train==i])\n",
    "    lengths.append(x_train_grouped[i].shape[0])\n",
    "\n",
    "minlength = np.min(np.array(lengths))\n",
    "for i in range(10):\n",
    "    x_train_grouped[i] = x_train_grouped[i][:minlength]\n",
    "x_train_grouped = einops.rearrange(x_train_grouped,\"numbers N b x y -> N (b numbers) () x y\")\n",
    "#print(x_train_grouped.shape)\n",
    "\n",
    "X0 = x_train_grouped[:,0]\n",
    "XT = x_train_grouped[:,1:]\n",
    "\n",
    "print(X0.shape)\n",
    "print(XT.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the Autoencoder structure as the right hand side of the ODE:\n",
    "- $\\frac{dy}{dt} = F_\\theta(t,y(t))$\n",
    "- In general we can use any function of this form: $F_\\theta:\\mathbb{R}^{1\\times N}\\rightarrow\\mathbb{R}^N$\n",
    "- Generally for good performance with Neural ODEs, we want $F$ to depend on $t$\n",
    "    - In this case we shall use a fully connected feedforward network on the time input and add this to the latent space in the autoencoder\n",
    "- When using a `eqx.Module` derived class in a neural ODE, we need the `__call__` method be of the form `(t,y,args)->y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(eqx.Module):\n",
    "    encode_layers: list\n",
    "    decode_layers: list\n",
    "    time_encode_layers: list\n",
    "    def __init__(self, key,channels=1):\n",
    "        key1, key2, key3, key4, key5, key6, key7,key8 = jax.random.split(key, 8)\n",
    "        # Standard CNN autoencoder - consecutive layers get narrower via MaxPool2d, and the expanded out again via ConvTranspose2d\n",
    "        # with a small MLP on top.\n",
    "        self.encode_layers = [\n",
    "            eqx.nn.Conv2d(channels, 8, kernel_size=6, key=key1),\n",
    "            eqx.nn.MaxPool2d(kernel_size=4),\n",
    "            jax.nn.gelu,\n",
    "            eqx.nn.Conv2d(8, 4, kernel_size=5, key=key2),\n",
    "            eqx.nn.MaxPool2d(kernel_size=4),\n",
    "            jax.nn.gelu,\n",
    "            eqx.nn.Conv2d(4, 4, kernel_size=4, key=key3),\n",
    "            eqx.nn.MaxPool2d(kernel_size=4),\n",
    "            jax.nn.gelu\n",
    "        ]\n",
    "        self.decode_layers = [\n",
    "            eqx.nn.ConvTranspose2d(4,4,kernel_size=4,key=key4),\n",
    "            jax.nn.gelu,\n",
    "            eqx.nn.ConvTranspose2d(4,8,kernel_size=5,stride=2,key=key5),\n",
    "            jax.nn.gelu,\n",
    "            eqx.nn.ConvTranspose2d(8,channels,kernel_size=6,key=key6),\n",
    "        ]\n",
    "        self.time_encode_layers = [\n",
    "            eqx.nn.Linear(1,100,key=key7),\n",
    "            jax.nn.gelu,\n",
    "            eqx.nn.Linear(100,196,key=key8),\n",
    "            jax.nn.tanh,\n",
    "            lambda x:einops.rearrange(x,\"(k kw kh)-> k kw kh\",kw=7,kh=7)\n",
    "        ]\n",
    "\n",
    "    def encode(self,x):\n",
    "        for L in self.encode_layers:\n",
    "            x = L(x)\n",
    "        return x\n",
    "    \n",
    "    def decode(self,x):\n",
    "        for L in self.decode_layers:\n",
    "            x = L(x)\n",
    "        return x\n",
    "    \n",
    "    def time_encode(self,t):\n",
    "        for L in self.time_encode_layers:\n",
    "            t = L(t)\n",
    "        return t\n",
    "    def __call__(self, t, y, args):\n",
    "        y = self.encode(y)\n",
    "        te = self.time_encode(np.array([t]))\n",
    "        y = y + te\n",
    "        y = self.decode(y)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define another `eqx.Module` subclass that solves an ODE\n",
    "- In the `__call__` method here we have `diffrax.diffeqsolve(...)`\n",
    "    - This uses a 5th order adaptive stepsize solver to much better approximate a continous ODE than euler's method (RNNs)\n",
    "- This `ODE_solver` also just works like any other `eqx.Module` - i.e. works with `grad`, `vmap`, `jit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODE_solver(eqx.Module):\n",
    "    update: Autoencoder\n",
    "\n",
    "\n",
    "    def __init__(self,key):\n",
    "        self.update = Autoencoder(key)\n",
    "        \n",
    "    def __call__(self, ts, y0):\n",
    "        solution = diffrax.diffeqsolve(\n",
    "            diffrax.ODETerm(self.update),\n",
    "            diffrax.Tsit5(),\n",
    "            t0=ts[0],\n",
    "            t1=ts[-1],\n",
    "            dt0=ts[1] - ts[0],\n",
    "            y0=y0,\n",
    "            stepsize_controller=diffrax.PIDController(rtol=1e-2, atol=1e-4),\n",
    "            saveat=diffrax.SaveAt(ts=ts),\n",
    "        )\n",
    "        return solution.ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the loss function\n",
    " - Here the `jax.vmap` is more subtle, as we want the same time input for all the different X inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_value_and_grad\n",
    "def loss(model,x0,xt):\n",
    "    v_model= jax.vmap(lambda y0:model(ts=np.arange(9),y0=y0),in_axes=0,out_axes=0,axis_name=\"BATCH\")\n",
    "    xt_predicted = v_model(x0)\n",
    "    \n",
    "    return np.mean((xt-xt_predicted)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the train method\n",
    " - This is pretty standard now - iterate through random batch samples of `X0` and `XT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,steps,LEARN_RATE=1e-2,BATCH_SIZE=32):\n",
    "    schedule = optax.exponential_decay(LEARN_RATE, transition_steps=steps, decay_rate=0.98)\n",
    "    optim = optax.adam(schedule)\n",
    "    opt_state = optim.init(eqx.filter(model, eqx.is_array))\n",
    "    loss_log = []\n",
    "    \n",
    "    @eqx.filter_jit # Wrap this in a filter_jit to speed things up\n",
    "    def make_step(model,opt_state,x0,xt):\n",
    "        \n",
    "        loss_value,grad = loss(model,x0,xt)\n",
    "        updates, opt_state = optim.update(grad, opt_state, model)\n",
    "        model = eqx.apply_updates(model, updates)\n",
    "        return model, opt_state, loss_value\n",
    "   \n",
    "    train_key = jr.fold_in(key,1)\n",
    "    for i in tqdm(range(steps)):\n",
    "        train_key = jr.fold_in(train_key,i)\n",
    "        # Choose which samples from x_train to fit to this iteration\n",
    "        inds = jr.choice(train_key,np.arange(5421),(BATCH_SIZE,),replace=False)\n",
    "        x0 = X0[inds]\n",
    "        xt = XT[inds]\n",
    "        \n",
    "        # Do the actual gradient update\n",
    "        model, opt_state, train_loss = make_step(model, opt_state, x0,xt)\n",
    "        loss_log.append(train_loss)\n",
    "        if i%10==0:\n",
    "            tqdm.write(\"Loss at step \"+str(i)+\": \"+str(train_loss))\n",
    "    \n",
    "    return model,loss_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ec7a7e50c8e468fa431ea9745eb026d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 0: 0.17896007\n",
      "Loss at step 10: 0.16287099\n"
     ]
    }
   ],
   "source": [
    "node = ODE_solver(key)\n",
    "model_trained,loss_log = train(node,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "XS = model_trained(np.linspace(0,9,100),X0[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6f980ee890>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(XS[99,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
